# ENTERPRISE BOT - Driscoll Fork
# All smart features OFF - dumb chatbot mode
# Memory pipeline dormant but available for future Pro tier

# =============================================================================
# DEPLOYMENT
# =============================================================================
deployment:
  mode: enterprise
  tier: basic              # basic = dumb, pro = memory, full = everything

# =============================================================================
# TENANT (Driscoll is first customer)
# =============================================================================
tenant:
  id: driscoll
  name: "Driscoll Foods"
  allowed_domains:
    - driscollfoods.com
    # NOTE: Add testing domains in .env or local config, not here
  docs_root: ./manuals/Driscoll
  default_division: warehouse

# =============================================================================
# FEATURE FLAGS - THE MASTER SWITCHES
# =============================================================================
features:
  # ==========================================================================
  # ENTERPRISE RAG - REMOVED
  # ==========================================================================
  # RAG has been replaced by context stuffing for Grok's 2M token window.
  # The RAG infrastructure (smart_tagger.py, smart_retrieval.py, embedder.py)
  # remains in the codebase but is dormant.
  # Database schema (enterprise.documents) is preserved but not used.
  #
  # enterprise_rag:
  #   enabled: false
  #   threshold: 0.6
  # ==========================================================================

  # CONTEXT STUFFING - Full manual injection (replaces RAG)
  # Takes advantage of Grok's 2M token context window
  context_stuffing:
    enabled: true
    doc_path: "./docs/driscoll"
    full_access_file: "all_manuals.txt"      # ~14.5k tokens (Sales+Purchasing+Warehouse)
    restricted_file: "sales_warehouse.txt"    # ~12k tokens (no purchasing)
    full_access_departments: ["purchasing"]   # These depts see ALL manuals
    cache_on_startup: true                    # Pre-load docs at boot

  # SQUIRREL - Session continuity (last hour awareness)
  # Gives Grok personality - "bro you asked that 5 times already"
  squirrel:
    enabled: true
    window_minutes: 60       # How far back to look
    max_exchanges: 10        # Cap for context size

  # MEMORY PIPELINES - INTENTIONALLY OMITTED
  # If not in config, EnterpriseTwin won't try to load it
  # Add this back for Pro tier:
  # memory_pipeline:
  #   enabled: true
  #   batch_interval: 5.0
  #   max_batch_size: 10

  # COGNITIVE FEATURES (ALL OFF for enterprise)
  metacognitive_mirror: false
  cognitive_profiler: false
  evolution_engine: false
  reasoning_traces: false
  chat_import: false

  # UI FEATURES
  ui:
    swarm_loop: false
    memory_space_3d: false
    chat_basic: true
    dark_mode: true
    analytics_dashboard: false

# =============================================================================
# USER TIERS (Personal SaaS)
# =============================================================================
tiers:
  free:
    messages_per_day: 20
    upload_enabled: true        # The hook - let them taste memory
    max_vault_size_mb: 100      # ~10k conversations
    features:
      - basic_chat
      - memory_upload
      - context_window_1m       # Use Grok's context

  premium:
    messages_per_day: -1        # Unlimited (-1)
    upload_enabled: true
    max_vault_size_mb: 10000    # 10GB - years of conversation
    features:
      - basic_chat
      - memory_upload
      - context_window_2m
      - memory_search
      - metacognitive_mirror
      - voice_mode
    price_monthly_usd: 20

# =============================================================================
# MODEL
# =============================================================================
model:
  provider: xai
  name: grok-4-1-fast-reasoning
  max_tokens: 8192
  temperature: 0.5              # Lower = more consistent
  context_window: 2000000

# =============================================================================
# DOCUMENT STUFFING
# =============================================================================
docs:
  docs_dir: ./manuals/Driscoll
  max_tokens_per_request: 200000
  include_shared: true

  stuffing:
    enabled: true
    max_tokens_per_division: 200000

# =============================================================================
# VOICE (Professional, not Venom)
# =============================================================================
voice:
  engine: venom                 # venom | enterprise
  style: corporate              # corporate | helpful | troll
  company_name: "Driscoll Foods"
  sign_off: false               # No "- Your AI Assistant" stuff
  default: corporate

  templates:
    corporate:
      personality: professional
      snark_level: 0

    troll:
      personality: sarcastic
      snark_level: 7

  division_voice:
    sales: corporate
    transportation: troll
    operations: corporate
    default: corporate

# =============================================================================
# VAULT STORAGE (B2)
# =============================================================================
vault:
  provider: b2
  bucket: ${B2_BUCKET_NAME}          # From .env
  key_id: ${B2_APPLICATION_KEY_ID}   # From .env
  app_key: ${B2_APPLICATION_KEY}     # From .env
  base_prefix: users                 # users/{user_uuid}/...

  # Subdirectories created per user
  structure:
    uploads: uploads      # Raw chat exports
    corpus: corpus        # Processed nodes.json
    vectors: vectors      # Embeddings .npy files
    indexes: indexes      # FAISS, clusters

# =============================================================================
# INGESTION PIPELINE (Personal tier)
# =============================================================================
ingestion:
  enabled: true

  # Embedding acceleration
  embedder:
    provider: deepinfra
    model: BAAI/bge-m3
    max_concurrent: 200           # DeepInfra limit - redline it
    batch_size: 32

  # Job queue (Redis)
  queue:
    redis_key_prefix: cogzy:jobs
    max_retries: 3
    job_timeout_seconds: 3600     # 1 hour max per upload

  # Deduplication
  dedup:
    enabled: true
    hash_fields:                  # Fields used for content hash
      - human_content
      - assistant_content
      - conversation_id

# =============================================================================
# PATHS
# =============================================================================
paths:
  # Local paths (enterprise mode / dev fallback)
  data_dir: ./data
  manuals_root: ./manuals

  # Personal tier uses vault paths instead
  # Resolved at runtime: vault.base_prefix/{user_id}/corpus/nodes.json

# =============================================================================
# RETRIEVAL (only when memory_pipelines: true - dormant)
# =============================================================================
retrieval:
  process_top_k: 10
  episodic_top_k: 5
  session_top_k: 5
  min_score: 0.3

# =============================================================================
# MEMORY PIPELINE (dormant - available for pro tier)
# =============================================================================
memory_pipeline:
  batch_interval: 5.0
  max_batch_size: 10

# =============================================================================
# MEMORY BACKEND (Phase 5)
# =============================================================================
memory:
  backend: file                 # "file" or "postgres"

  # PostgreSQL configuration (only needed if backend = "postgres")
  postgres:
    host: localhost
    port: 5432
    database: enterprise_bot
    user: postgres
    password: ${POSTGRES_PASSWORD}  # Use env var for secrets

# =============================================================================
# LOGGING
# =============================================================================
logging:
  level: INFO
  format: "%(asctime)s [%(levelname)s] %(name)s: %(message)s"
